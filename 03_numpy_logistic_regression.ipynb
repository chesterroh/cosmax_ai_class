{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지난번 01_mnist_dataset_numpy 노트북을 성공적으로 수행하신 분들이라면 mnist dataset 중에서 0,1 로만 이루어진 x_train, y_train 을 만드셨을텐데요. 오늘을 이를 이용해서 numpy 를 가지고 logistic regression 을 한번 구현해보도록 합시다. ( 지난번 linear regression 과 마찬가지로 마지막에는 pytorch 를 이용해서도 한번 구현해보도록 하겠습니다. )\n",
    "\n",
    "그럼 먼저 데이터셋을 한번 준비해볼까요? 지난번 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://yann.lecun.com/exdb/mnist/ downloaded train-images-idx3-ubyte.gz\n",
      "http://yann.lecun.com/exdb/mnist/ downloaded t10k-images-idx3-ubyte.gz\n",
      "http://yann.lecun.com/exdb/mnist/ downloaded train-labels-idx1-ubyte.gz\n",
      "http://yann.lecun.com/exdb/mnist/ downloaded t10k-labels-idx1-ubyte.gz\n",
      "download has been completed.\n",
      "(60000, 28, 28)\n",
      "(60000, 1)\n",
      "(10000, 28, 28)\n",
      "(10000, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from urllib import request\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "\n",
    "filename = [\n",
    "[\"x_train\", \"train-images-idx3-ubyte.gz\"],\n",
    "[\"x_test\", \"t10k-images-idx3-ubyte.gz\"],\n",
    "[\"y_train\", \"train-labels-idx1-ubyte.gz\"],\n",
    "[\"y_test\", \"t10k-labels-idx1-ubyte.gz\" ],\n",
    "]\n",
    "\n",
    "base_url = \"http://yann.lecun.com/exdb/mnist/\"\n",
    "\n",
    "# CHALLENGE 연습문제 ( 해보고 싶은 분들은 만들어보세요. )\n",
    "# 매번 Lecun 교수님의 홈페이지에 가서 dataset 을 다운로드 해오는 것은 큰 낭비입니다. \n",
    "# 이미 다운로드한 파일들이 있을때 다운로드를 안해도 되도록 코드를 수정해봅시다 :)\n",
    "\n",
    "\n",
    "# filename list 에서 하나씩 file 이름들을 가져옵니다. \n",
    "for n in filename:\n",
    "    request.urlretrieve(base_url+n[1],n[1])\n",
    "    print(\"%s downloaded \" % base_url+n[1])\n",
    "\n",
    "print(\"download has been completed.\")\n",
    "\n",
    "# dictionary 에 'x_train', 'y_train', 'x_test', 'y_test' 라는 key 로 저장합니다.\n",
    "mnist = {}\n",
    "\n",
    "# train, test image 를 가져와서 dictionary 에 넣습니다.  x_train, y_train 에 넣습니다. \n",
    "for name in filename[:2]:\n",
    "    with gzip.open(name[1], 'rb') as f:\n",
    "        mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1,28,28)\n",
    "        \n",
    "for name in filename[2:]:\n",
    "    with gzip.open(name[1], 'rb') as f:\n",
    "        mnist[name[0]] = np.frombuffer(f.read(),np.uint8, offset=8).reshape(-1,1)\n",
    "        \n",
    "# training data, label 의 shape 을 살펴봅시다. \n",
    "print(mnist['x_train'].shape)\n",
    "print(mnist['y_train'].shape)\n",
    "\n",
    "# test data, label 의 shape 을 살펴볼까요?\n",
    "print(mnist['x_test'].shape)\n",
    "print(mnist['y_test'].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터넷은 0 에서 9 까지의 모든 숫자들을 담고 있습니다. 여기에서 0,1 만으로 이루어져 있는 dataset 을 만들어 볼까요? \n",
    "x_train, y_train, x_test, y_test 를 만들어 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12665, 28, 28) (12665, 1)\n",
      "(2115, 28, 28) (2115, 1)\n"
     ]
    }
   ],
   "source": [
    "def dataset_filter( x, y ):  \n",
    "    mask = y < 2\n",
    "    mask = mask.T\n",
    "    mask = mask[0]  # 역설적이면 rank-1 row vector 로 변경함 \n",
    "    return x[mask,:], y[mask,:]\n",
    "\n",
    "x_train, y_train = dataset_filter( mnist['x_train'], mnist['y_train'])\n",
    "x_test, y_test = dataset_filter( mnist['x_test'], mnist['y_test'])\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "총 60,000 개의 데이터셋에서 0,1 데이터만 꺼내니까  training set 은 12,665개, test set은 2,115 개의 데이터만 남는군요. 제대로 처리가 되었는지 테스트해볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAMb0lEQVR4nO3dbYxcZRnG8euillaKhFa0NlgtSn0hGqvZFBE0GIIWNBZ8IdSE1EiyaiDRBKMoJPLBD0TxXYNZpFIVURIkNJGotSEiCYEuWPpC1WLTpq1LKzaBKtpuy+2HPZgFds5s55wzZ+j9/yWTmTn3zDx3Jr16zpxndh5HhAAc+45ruwEA/UHYgSQIO5AEYQeSIOxAEi/p52DHe1bM1px+Dgmk8l/9W4fioKeqVQq77WWSviNphqQfRcT1ZY+frTk60+dVGRJAiQdiXcdaz4fxtmdI+oGkCySdIWmF7TN6fT0AzarymX2ppMciYntEHJL0C0nL62kLQN2qhP1USbsm3d9dbHsO28O2R22PjutgheEAVNH42fiIGImIoYgYmqlZTQ8HoIMqYd8jaeGk+68utgEYQFXCvl7SYtun2T5e0qWS1tTTFoC69Tz1FhGHbV8p6beamHpbFRFbausMQK0qzbNHxN2S7q6pFwAN4uuyQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiTR1yWbgcl2fPWs0vpfPnljaX3xzz5TWn/dF+4/6p6OZezZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJ5tnRqBlvPL1j7cqLyxcAHo8j5S8evXSUV6Ww294h6YCkI5IOR8RQHU0BqF8de/b3RsQTNbwOgAbxmR1IomrYQ9LvbD9ke3iqB9getj1qe3RcBysOB6BXVQ/jz4mIPbZfKWmt7T9HxL2THxARI5JGJOkkz+OUCtCSSnv2iNhTXO+TdKekpXU0BaB+PYfd9hzbL3v2tqT3SdpcV2MA6lXlMH6+pDttP/s6P4+I39TSFY4ZJ6/6Z8fap0/e3sdO0HPYI2K7pLfV2AuABjH1BiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASLNmMcsfNKC3vvK58XZCbFn69pPrS0ueu2P7+0vobvruztH64tJoPe3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJ5dpT6+1VnltY3Xf69Lq9QPpde5slrF5bWj9vzp55fO6Oue3bbq2zvs7150rZ5ttfa3lZcz222TQBVTecw/hZJy5637WpJ6yJisaR1xX0AA6xr2CPiXkn7n7d5uaTVxe3Vki6qty0Adev1M/v8iBgrbj8uaX6nB9oeljQsSbN1Qo/DAaiq8tn4iAhJUVIfiYihiBiaqVlVhwPQo17Dvtf2AkkqrvfV1xKAJvQa9jWSVha3V0q6q552ADSl62d227dJOlfSKbZ3S/qKpOsl3W77ckk7JV3SZJNoz0nnPd52C6hJ17BHxIoOpfNq7gVAg/i6LJAEYQeSIOxAEoQdSIKwA0nwJ65ozcXbPlhaP/6xvaV1fir66LBnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkmGdPbtv3y38qevNbuv1UdPmSzudv+UjH2uwP/L30uTF+qMvYOBrs2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCebZj3G7rnlXaX3zRd8urc90+Tx6N0d+2HFlMMX4jkqvjaPDnh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCe/Rgw4/TTOtbO/tAjpc+tOo8+8uSi0vqcXU93rEWlkXG0uu7Zba+yvc/25knbrrO9x/aG4nJhs20CqGo6h/G3SFo2xfZvRcSS4nJ3vW0BqFvXsEfEvZL296EXAA2qcoLuStsbi8P8uZ0eZHvY9qjt0XEdrDAcgCp6DfuNkl4vaYmkMUnf6PTAiBiJiKGIGJqpWT0OB6CqnsIeEXsj4khEPCPpJklL620LQN16CrvtBZPuXixpc6fHAhgMXefZbd8m6VxJp9jeLekrks61vUQTU6U7JH2quRax+0vlf5P+0Uv/0LF27SkbK4395tuuKK2f/st/l9Zj/aZK46M+XcMeESum2HxzA70AaBBflwWSIOxAEoQdSIKwA0kQdiAJ/sT1ReDpReOl9arTa2XmPurSOlNrLx7s2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCebZB8HSt5aWV59/U2NDv+3+laX1Rb/+W2n9SJ3NoFHs2YEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCebZ++DpD59ZWt97yX9K62fN6n02+9xNHyutv2bFX0vrR8YP9Tw2Bgt7diAJwg4kQdiBJAg7kARhB5Ig7EAShB1Ignn2Phg7q/z/1K3v/nFjYx9Y+6rS+onj2xsbG4Ol657d9kLb99h+1PYW258tts+zvdb2tuJ6bvPtAujVdA7jD0u6KiLOkPROSVfYPkPS1ZLWRcRiSeuK+wAGVNewR8RYRDxc3D4gaaukUyUtl7S6eNhqSRc11COAGhzVZ3bbiyS9XdIDkuZHxFhRelzS/A7PGZY0LEmzdULPjQKoZtpn422fKOkOSZ+LiKcm1yIiJMVUz4uIkYgYioihmZpVqVkAvZtW2G3P1ETQb42IXxWb99peUNQXSNrXTIsA6tD1MN62Jd0saWtEfHNSaY2klZKuL67vaqRDdDXy5KKOtQV/PNC/RjDQpvOZ/WxJl0naZHtDse3Lmgj57bYvl7RT0iWNdAigFl3DHhH3SXKH8nn1tgOgKXxdFkiCsANJEHYgCcIOJEHYgST4E9cavOS1C0vrn3j/PY2Of8Mfl3WsveHB9Y2OjRcP9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATz7DU4vHNXaf2W3763tP7Fj28prb/jwctK62/6/J871p4pfSYyYc8OJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0l4YjGX/jjJ8+JM84O0QFMeiHV6KvZP+WvQ7NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IImuYbe90PY9th+1vcX2Z4vt19neY3tDcbmw+XYB9Go6P15xWNJVEfGw7ZdJesj22qL2rYi4obn2ANRlOuuzj0kaK24fsL1V0qlNNwagXkf1md32Iklvl/RAselK2xttr7I9t8Nzhm2P2h4d18Fq3QLo2bTDbvtESXdI+lxEPCXpRkmvl7REE3v+b0z1vIgYiYihiBiaqVnVOwbQk2mF3fZMTQT91oj4lSRFxN6IOBIRz0i6SdLS5toEUNV0zsZb0s2StkbENydtXzDpYRdL2lx/ewDqMp2z8WdLukzSJtsbim1flrTC9hJJIWmHpE810B+AmkznbPx9kqb6+9i7628HQFP4Bh2QBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJvi7ZbPsfknZO2nSKpCf61sDRGdTeBrUvid56VWdvr42IV0xV6GvYXzC4PRoRQ601UGJQexvUviR661W/euMwHkiCsANJtB32kZbHLzOovQ1qXxK99aovvbX6mR1A/7S9ZwfQJ4QdSKKVsNteZvsvth+zfXUbPXRie4ftTcUy1KMt97LK9j7bmydtm2d7re1txfWUa+y11NtALONdssx4q+9d28uf9/0zu+0Zkv4q6XxJuyWtl7QiIh7tayMd2N4haSgiWv8Chu33SPqXpJ9ExFuKbV+TtD8iri/+o5wbEV8ckN6uk/SvtpfxLlYrWjB5mXFJF0n6hFp870r6ukR9eN/a2LMvlfRYRGyPiEOSfiFpeQt9DLyIuFfS/udtXi5pdXF7tSb+sfRdh94GQkSMRcTDxe0Dkp5dZrzV966kr75oI+ynSto16f5uDdZ67yHpd7Yfsj3cdjNTmB8RY8XtxyXNb7OZKXRdxrufnrfM+MC8d70sf14VJ+he6JyIeIekCyRdURyuDqSY+Aw2SHOn01rGu1+mWGb8/9p873pd/ryqNsK+R9LCSfdfXWwbCBGxp7jeJ+lODd5S1HufXUG3uN7Xcj//N0jLeE+1zLgG4L1rc/nzNsK+XtJi26fZPl7SpZLWtNDHC9ieU5w4ke05kt6nwVuKeo2klcXtlZLuarGX5xiUZbw7LTOult+71pc/j4i+XyRdqIkz8n+TdE0bPXTo63WSHikuW9ruTdJtmjisG9fEuY3LJb1c0jpJ2yT9XtK8Aertp5I2SdqoiWAtaKm3czRxiL5R0obicmHb711JX3153/i6LJAEJ+iAJAg7kARhB5Ig7EAShB1IgrADSRB2IIn/AbKpuYnJ1U5RAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 100 번째 index 에 들어있는 데이터를 한번 출력해봅시다. \n",
    "img = x_train[99,:]\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "# Label 과 매치하는지 살펴볼까요? \n",
    "print(y_train[99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자 이제 numpy 를 이용해서 dataset 준비는 제대로 완료되었습니다. 이제 logistic regression 을 구현해보도록 합시다.\n",
    "\n",
    "28 x 28 이미지로 되어있는 2차원의 이미지를 28 * 28 (784) 개의 1D array 로 한번 Flatten 시켜볼까요? 2차원, 3차원으로 구성되어 있는 데이터를 1차원의 column vector 로 쭉 펼치는 과정을 Flatten 한다고 이야기합니다. 나중에 Neural Net 에서 Convolutional Neural Network 에서 Fully Connected Layer 로 연결할때 Flatten 을 사용하게 됩니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12665, 28, 28) (12665, 1)\n",
      "(2115, 28, 28) (2115, 1)\n",
      "(784, 12665) (1, 12665)\n",
      "(784, 2115) (1, 2115)\n"
     ]
    }
   ],
   "source": [
    "# 0~255 로 되어 있는 값을 0~1 사이로 normalize 해줍니다.\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "# dataset 의 dimension 을  ( n_x * m ), label 의 dimension 을 ( 1 * m) 으로 변경합니다.\n",
    "# 왜 이렇게 만드는지는 '이론교육자료'를 참고하도록 합시다. :)  matrix dimension 맞추기가 머리가 아파오기 시작하시죠 ㅎㅎㅎ \n",
    "x_train, y_train = x_train.reshape(-1,28*28).T, y_train.T\n",
    "x_test, y_test = x_test.reshape(-1,28*28).T, y_test.T\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 Logistic regression 의 본격적인 training 을 시작해볼까요.\n",
    "\n",
    "__( 여기 즈음에서 Logistic Regression 의 이론교육자료를 첨부할 예정입니다. \n",
    "  이론교육자료는 아직 만들지를 않아서 만들고 나면 이곳에 링크를 첨부해두도록 하겠습니다. )__\n",
    "\n",
    "입력하는 데이터셋의 feature 의 갯수는 X1, X2, ...., X784 까지 총 784 개이고, training dataset 의 갯수는 12,665 개가 되겠네요.  training dataset 의 용량을 계산해보면 ( 12665 * 784 bytes 인데 ) 약 9MB 정도밖에 안하네요. 따로 mini-batch 를 나눌필요없이 전체의 dataset 을 하나의 epoch 으로 다 처리하는데 무리가 없을 것 같네요.\n",
    "\n",
    "입력데이터의 feature dimension 이 784 이기 때문에, weight 는 784 개의 column vector 를 만들면 되겠고, bias 는 real number 1 개만 있으면 되겠네요. \n",
    "\n",
    "__( mini-batch 의 개념은 hidden layer 가 존재하는 제대로 된 neural network 을 만들때 구현해보도록 하겠습니다. )__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 347.837600\n",
      "epoch: 1, loss: 346.679480\n",
      "epoch: 2, loss: 345.536516\n",
      "epoch: 3, loss: 344.408650\n",
      "epoch: 4, loss: 343.295820\n",
      "epoch: 5, loss: 342.197965\n",
      "epoch: 6, loss: 341.115017\n",
      "epoch: 7, loss: 340.046909\n",
      "epoch: 8, loss: 338.993570\n",
      "epoch: 9, loss: 337.954928\n",
      "epoch: 10, loss: 336.930907\n",
      "epoch: 11, loss: 335.921430\n",
      "epoch: 12, loss: 334.926419\n",
      "epoch: 13, loss: 333.945792\n",
      "epoch: 14, loss: 332.979465\n",
      "epoch: 15, loss: 332.027354\n",
      "epoch: 16, loss: 331.089371\n",
      "epoch: 17, loss: 330.165429\n",
      "epoch: 18, loss: 329.255436\n",
      "epoch: 19, loss: 328.359301\n",
      "epoch: 20, loss: 327.476929\n",
      "epoch: 21, loss: 326.608227\n",
      "epoch: 22, loss: 325.753096\n",
      "epoch: 23, loss: 324.911440\n",
      "epoch: 24, loss: 324.083159\n",
      "epoch: 25, loss: 323.268153\n",
      "epoch: 26, loss: 322.466319\n",
      "epoch: 27, loss: 321.677555\n",
      "epoch: 28, loss: 320.901758\n",
      "epoch: 29, loss: 320.138821\n",
      "epoch: 30, loss: 319.388641\n",
      "epoch: 31, loss: 318.651109\n",
      "epoch: 32, loss: 317.926118\n",
      "epoch: 33, loss: 317.213561\n",
      "epoch: 34, loss: 316.513327\n",
      "epoch: 35, loss: 315.825308\n",
      "epoch: 36, loss: 315.149394\n",
      "epoch: 37, loss: 314.485473\n",
      "epoch: 38, loss: 313.833436\n",
      "epoch: 39, loss: 313.193169\n",
      "epoch: 40, loss: 312.564561\n",
      "epoch: 41, loss: 311.947501\n",
      "epoch: 42, loss: 311.341875\n",
      "epoch: 43, loss: 310.747570\n",
      "epoch: 44, loss: 310.164475\n",
      "epoch: 45, loss: 309.592476\n",
      "epoch: 46, loss: 309.031459\n",
      "epoch: 47, loss: 308.481313\n",
      "epoch: 48, loss: 307.941924\n",
      "epoch: 49, loss: 307.413178\n",
      "epoch: 50, loss: 306.894964\n",
      "epoch: 51, loss: 306.387168\n",
      "epoch: 52, loss: 305.889678\n"
     ]
    }
   ],
   "source": [
    "# sigmoid 함수를 정의합니다. \n",
    "def sigmoid_f( x ):\n",
    "    return 1/(1+np.exp(-x))\n",
    "# cross-entropy loss 함수를 정의합니다. \n",
    "def loss_f( a, y ):\n",
    "    return -(np.dot(y.T,np.log(a)) + np.dot((1 - y.T),np.log(1- a)))\n",
    "    \n",
    "# hyper parameter 를 정의합니다. \n",
    "epoch = 100\n",
    "learning_rate = 0.0001\n",
    "m = len(x_train)  # dataset 의 갯수를 의미합니다. \n",
    "\n",
    "# 학습을 시킬 parameter  를 준비합니다. \n",
    "w = np.random.normal(0, 0.25 ,size=(784,1)) # np.random.random((784,1))\n",
    "b = np.zeros((1,1)) # np.random.random((1))\n",
    "\n",
    "loss_trail = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    z = np.dot(w.T, x_train) + b\n",
    "    a = sigmoid_f(z)\n",
    "    loss = loss_f(a,y_train)/m\n",
    "    print(\"epoch: %d, loss: %f\" %(i,np.sum(loss)/m))\n",
    "    loss_trail.append(loss)\n",
    "    dz = a - y_train\n",
    "    db = 1/m * np.sum(dz)\n",
    "    dw = 1/m * np.dot(x_train, dz.T)\n",
    "    \n",
    "    w = w - learning_rate * dw\n",
    "    b = b - learning_rate * db\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss 가 제대로 떨어지는지 한번 그래프를 그려보도록 합시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(loss_trail)), loss_trail)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
