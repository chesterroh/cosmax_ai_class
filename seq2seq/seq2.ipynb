{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import spacy\n",
    "\n",
    "from torchtext.datasets import IMDB, AG_NEWS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train, test = AG_NEWS(split=('train','test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "tokenizer_en = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "tokenizer_de = get_tokenizer('spacy', language='de_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter):\n",
    "    for label, text in data_iter:\n",
    "        yield tokenizer_en(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab_from_iterator(yield_tokens(train), min_freq=2, specials=['<unk>', '<pad>', '<sos>', '<eos>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62544"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[540, 27, 4, 6113]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab([ 'here', 'is' , 'the', 'example' ] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n"
     ]
    }
   ],
   "source": [
    "vocab(['<sos>', 'what', 'the', 'fuck', 'is' , 'that', '<eos>'])\n",
    "\n",
    "PAD_IDX = vocab['<pad>']\n",
    "SOS_IDX = vocab['<sos>']\n",
    "EOS_IDX = vocab['<eos>']\n",
    "\n",
    "print(PAD_IDX, SOS_IDX, EOS_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "devce = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x : vocab(tokenizer_en(x))\n",
    "label_pipeline = lambda x : int(x) - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_pipeline(_label))\n",
    "        processed_text = torch.tensor( text_pipeline(_text), dtype=torch.int64)\n",
    "        text_list.append(torch.cat( [torch.tensor([SOS_IDX]), processed_text, torch.tensor([EOS_IDX])], dim=0))\n",
    "    label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "    text_list = pad_sequence( text_list, padding_value=PAD_IDX )\n",
    "    return label_list, text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "a = torch.tensor([2])\n",
    "b = torch.rand(10)\n",
    "c = torch.tensor([3])\n",
    "torch.cat( [a,b,c] , dim=0 ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = AG_NEWS(split=('train','test'))\n",
    "train_loader = DataLoader(train, batch_size=8, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " tensor([[    2,     2,     2,     2,     2,     2,     2,     2],\n",
       "         [  448, 17833,   168,    76,   168,   350,  2662,  1384],\n",
       "         [  574,  5254,    12, 13733,   110,  1307,  4300,  1280],\n",
       "         [ 2060,  6389,  2766,   168,  7054,   325, 12847,   600],\n",
       "         [50439,  7996, 12832,  9297,     7,     5,    11, 17529],\n",
       "         [ 1199, 10809,   350,    34,   132,   378,  3789,    46],\n",
       "         [ 1721,    17,    78, 12877,     8,  1964,  1906,  1661],\n",
       "         [    4,    33,  1956,  1592,    96,  1126,    17,    17],\n",
       "         [ 1383,    18,    17,  8215,   151,  7232,    36,  2254],\n",
       "         [   17,    33,    33,    17,     5,    17,    18,    18],\n",
       "         [   33,     8,    18,    33,  8588,    33,    36,  2254],\n",
       "         [   18,  5027,    33,    18,    45,    18,     8,     8],\n",
       "         [   33,   932,     8,    33, 15532,    33, 10133,  3243],\n",
       "         [    8,   357, 10361,     8,     7,     8,    10,   165],\n",
       "         [ 4036, 17833,   717,  7292,    41,   350,     4,  7097],\n",
       "         [    8,     0,   110,    44,   396,   754,   394,   122],\n",
       "         [10270,    31,  4564,  6116,    17,  1485,    25,     9],\n",
       "         [    5,     9, 32386,    99,   102,   332,  1090,  1862],\n",
       "         [  448,  5047,     4,     0,    18,    13,   773,    11],\n",
       "         [  423,    14,   396,    34,   102,     0,   142,  1218],\n",
       "         [   25,   517,    12,     4,     8,  4859,  2457,     5],\n",
       "         [    0,   531,     4,   927,     0,   414,  1617,    12],\n",
       "         [   10,     8,  1189,  3950,    93,  3058,   434,    45],\n",
       "         [ 8380, 17105,    14,    11,    99,    14,    30,   696],\n",
       "         [    8,    12,   329,   805,   110,     4,    15,    14],\n",
       "         [39312,     0,    48,    76,     5,    50,    16,  4336],\n",
       "         [    5,  2672,   190,     0, 12505,    23, 48500,  1922],\n",
       "         [   48,    11, 62040,   664,  2109,    99,   144,   434],\n",
       "         [ 4739,     4,    46,     9,    12,   110,    11,    80],\n",
       "         [ 3037,   802,     4,   928, 18361,  2403,     4,    90],\n",
       "         [  375,   263,   391,  3167, 10996,   392,   328,     5],\n",
       "         [    6,     5,   142,   100,     5,    15,    90,     4],\n",
       "         [    3,    31,   119,     0,  4109,    16,     7,   106],\n",
       "         [    1,  4401,    90,     5,     9,     0,    15,    29],\n",
       "         [    1,     0,   210,    37,    45,   744,    16,    63],\n",
       "         [    1,  8669,     4,    99,   425,     5,     0,     5],\n",
       "         [    1,    13,  7432,   310, 15532, 15545,  7285,  8060],\n",
       "         [    1,   223,    10,    29,  4002,     9,     5,     4],\n",
       "         [    1,   356, 47845,    13,    92,  1851,     4,   396],\n",
       "         [    1,    10, 18188,   120,   278,  1189,  4173,    27],\n",
       "         [    1,     4,     6,     6,   174,    34,  1261,  2948],\n",
       "         [    1,   142,     3,     3,     4,   295,  3487,    34],\n",
       "         [    1,     6,     1,     1,    41,     0,    29,     9],\n",
       "         [    1,     3,     1,     1,   422,    72,    63, 31851],\n",
       "         [    1,     1,     1,     1,   594,    17,     6,  4858],\n",
       "         [    1,     1,     1,     1,     6, 15250,     3,     6],\n",
       "         [    1,     1,     1,     1,     3,    18,     1,     3],\n",
       "         [    1,     1,     1,     1,     1,     3,     1,     1]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
